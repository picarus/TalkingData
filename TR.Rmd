---
title: "R Notebook"
output: html_notebook
---

```{r}
# library(pacman)
# p_load(ggplot2) # Data visualization
# p_load(readr) # CSV file I/O, e.g. the read_csv function
# p_load(dplyr)
# library(multidplyr)
# p_load(parallel)
# p_load(fasttime)
# p_load(xgboost)
# p_load(mlr)
# p_load(mlrMBO)
# p_load(caret)
# p_load(magrittr)
# p_load(parallelMap)
# p_load(DiceKriging)
# p_load(rgenoud)


# Input data files are available in the "../input/" directory.
# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory
#devtools::install_github("hadley/multidplyr")
```


```{r}
print(n_cores <- detectCores()-1)
```

# train, validation 

```{r}
table(valid_cv$is_attributed)
```

```{r}
table(train_cv$is_attributed)
```

```{r}
set.seed(0)
```


```{r}
params <- getParamSet("classif.xgboost")
params
```

```{r}
xgb_param <- makeParamSet(
  makeIntegerParam("max_depth", lower = 1, upper = 10),  # number of splits in each tree
  makeNumericParam("eta", lower = .1, upper = .8), # "shrinkage" - prevents overfitting
  makeNumericParam("lambda", lower = -1, upper = 0, trafo = function(x) 10^x) # L2 regularization - prevents overfitting
)
```

```{r}
# mlrMBO part
mboControl <- makeMBOControl()
mboControl <- setMBOControlTermination(mboControl, iters = 1)  # in addition to the initials
mboControl <- setMBOControlInfill(mboControl, crit = makeMBOInfillCritAEI()) # augmented expected improvement
# mlr part
tuneMBOControl <- makeTuneControlMBO(mbo.control = mboControl)
```


## Dynamic setup


```{r}

train_cv_matrix <- xgboost::xgb.DMatrix(data=data.matrix(train_cv %>% select(-is_attributed, -wghts)),
                                        label=train_cv$is_attributed, missing = NA, weight=train_cv$wghts)
valid_cv_matrix <- xgboost::xgb.DMatrix(data=data.matrix(valid_cv %>% select(-is_attributed, -wghts)),
                                        label=valid_cv$is_attributed, missing = NA, weight=valid_cv$wghts)

xgb <- makeLearner( "classif.xgboost", 
                    predict.type = "prob",
                    par.vals = list(
                      objective = "binary:logistic",
                      eval_metric = "auc",
                      watchlist = list( train = train_cv_matrix, val = valid_cv_matrix),
                      nrounds = 50, 
                      maximize = T,
                      verbose = 1, 
                      nthread = n_cores,
                      print_every_n = 5,
                      early_stopping_rounds = 5)
                    )

```

```{r}
trainTask <- makeClassifTask(data = train_cv %>% select(-wghts), target = "is_attributed", positive = 1)
```


```{r}

resTune <- tuneParams(learner=xgb, 
                task=trainTask, 
                resampling=makeResampleDesc("Subsample", iters = 2, split = 0.95),
                # TODO: PROVIDE resample.fun
                measures=auc, 
                par.set = xgb_param, 
                control = tuneMBOControl, 
                show.info = F)
```

```{r}
xgb_tuned_learner <- setHyperPars(learner = xgb, par.vals = resTune$x)

xgb_model <- train(xgb_tuned_learner, trainTask)
```


 